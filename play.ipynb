{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accelerator                   Model     Cycles Runtime (s)  \\\n",
      "0        nvdla  test_layer_VGG16_conv1     612721      0.0018   \n",
      "1        nvdla      test_layer_BERT_qk      13313      0.0000   \n",
      "2        nvdla     test_layer_BERT_ffn     294913      0.0008   \n",
      "3        nvdla       test_model_YOLOv8    4571206      0.0131   \n",
      "4        nvdla  test_model_MobileNetv3    1132209      0.0032   \n",
      "5        nvdla    test_model_MobileViT     323590      0.0009   \n",
      "6        nvdla        test_model_VGG16   48072056      0.1373   \n",
      "7        nvdla  test_model_InceptionV3    2843144      0.0081   \n",
      "8   shidiannao  test_layer_VGG16_conv1   15770881      0.0451   \n",
      "9   shidiannao      test_layer_BERT_qk      24576      0.0001   \n",
      "10  shidiannao     test_layer_BERT_ffn      55296      0.0002   \n",
      "11  shidiannao       test_model_YOLOv8   16137681      0.0461   \n",
      "12  shidiannao  test_model_MobileNetv3    5648773      0.0161   \n",
      "13  shidiannao    test_model_MobileViT     602112      0.0017   \n",
      "14  shidiannao        test_model_VGG16  148925953      0.4255   \n",
      "15  shidiannao  test_model_InceptionV3    7430568      0.0212   \n",
      "16     eyeriss  test_layer_VGG16_conv1     522145      0.0015   \n",
      "17     eyeriss      test_layer_BERT_qk      17408      0.0000   \n",
      "18     eyeriss     test_layer_BERT_ffn    2506753      0.0072   \n",
      "19     eyeriss       test_model_YOLOv8    7759122      0.0222   \n",
      "20     eyeriss  test_model_MobileNetv3    1757385      0.0050   \n",
      "21     eyeriss    test_model_MobileViT     450560      0.0013   \n",
      "22     eyeriss        test_model_VGG16   70662056      0.2019   \n",
      "23     eyeriss  test_model_InceptionV3    5712968      0.0163   \n",
      "\n",
      "                EDP  Memory Access Reuse Factor  Power Proxy  \n",
      "0       319596.0942      612652178      10.4925  104382.6410  \n",
      "1          221.0067       21273980       9.0024  152852.9696  \n",
      "2        25002.4025       71681750       6.0069   35315.1869  \n",
      "3     26189629.6202     7231279680       9.2958  153633.7506  \n",
      "4      1158487.2000     1269431602       8.1605  110806.7554  \n",
      "5       131316.1675      518714008       9.0229  153725.7811  \n",
      "6   1757600034.1162    42424850090       8.0206   93268.8526  \n",
      "7      6402459.9704     2853692386       8.3241   97125.3566  \n",
      "8      7874195.3562     1720559858   16430.3156    3978.2015  \n",
      "9          239.9097       31203712      43.6718   48758.8200  \n",
      "10        3915.2673       95165568       1.3939  156959.2297  \n",
      "11    56771578.1370    11086105586    7548.8898   26804.5216  \n",
      "12     5693095.8893     6759326488    1596.3620   21956.2848  \n",
      "13      143027.8123      763654400     262.3341   48428.3557  \n",
      "14  4902937480.4185   259951363322    5238.7841   27180.1876  \n",
      "15    13004490.0685    12780315864     325.1930   28952.6289  \n",
      "16      223624.4136      514906332      41.8464  100578.4799  \n",
      "17         261.1554       30588928      85.6667  105669.2235  \n",
      "18      208523.6769       72277258    1024.6667    4165.0733  \n",
      "19    40478055.3936     8821251328      58.4547   82462.6987  \n",
      "20     1524895.4581     1254123268      33.3958   60584.2541  \n",
      "21      166645.8245      949860096      77.6254  100659.9986  \n",
      "22  2003421424.2273    35003349956     421.8098   49251.3967  \n",
      "23    10268302.0276     2278826150      71.2719   38639.9494  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuration for accelerators and models\n",
    "accelerators = [\"nvdla\", \"shidiannao\", \"eyeriss\"]\n",
    "models = [\n",
    "    \"test_layer_VGG16_conv1\",\n",
    "    \"test_layer_BERT_qk\",\n",
    "    \"test_layer_BERT_ffn\",\n",
    "    \"test_model_YOLOv8\",\n",
    "    \"test_model_MobileNetv3\",\n",
    "    \"test_model_MobileViT\",\n",
    "    \"test_model_VGG16\",\n",
    "    \"test_model_InceptionV3\"\n",
    "]\n",
    "\n",
    "dataflow_mapping = {\n",
    "    \"nvdla\": \"ykp_os\",\n",
    "    \"shidiannao\": \"kcp_ws\",\n",
    "    \"eyeriss\": \"rs\"\n",
    "}\n",
    "\n",
    "freq_MHz = 350  # Frequency in MHz\n",
    "freq_Hz = freq_MHz * 1e6\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "for accelerator in accelerators:\n",
    "    \n",
    "    for model in models:\n",
    "        # Dynamically construct the file path\n",
    "        file_path = f'out/{accelerator}/{accelerator}_{model}_{dataflow_mapping[accelerator]}.csv'\n",
    "        \n",
    "        try:\n",
    "            # Read CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Extract column indices dynamically\n",
    "            runtime_col = df.columns.get_loc(' Runtime (Cycles)')\n",
    "            input_l1_read_col = df.columns.get_loc(' input l1 read')\n",
    "            input_l1_write_col = df.columns.get_loc(' input l1 write')\n",
    "            filter_l1_read_col = df.columns.get_loc('filter l1 read')\n",
    "            filter_l1_write_col = df.columns.get_loc(' filter l1 write')\n",
    "            output_l1_read_col = df.columns.get_loc('output l1 read')\n",
    "            output_l1_write_col = df.columns.get_loc(' output l1 write')\n",
    "            input_l2_read_col = df.columns.get_loc(' input l2 read')\n",
    "            input_l2_write_col = df.columns.get_loc(' input l2 write')\n",
    "            filter_l2_read_col = df.columns.get_loc(' filter l2 read')\n",
    "            filter_l2_write_col = df.columns.get_loc(' filter l2 write')\n",
    "            output_l2_read_col = df.columns.get_loc(' output l2 read')\n",
    "            output_l2_write_col = df.columns.get_loc(' output l2 write')\n",
    "            offchip_bw_col = df.columns.get_loc(' Offchip BW Req (Elements/cycle)')\n",
    "            reuse_input_col = df.columns.get_loc(' input reuse factor')\n",
    "            reuse_filter_col = df.columns.get_loc(' filter reuse factor')\n",
    "            reuse_output_col = df.columns.get_loc(' output reuse factor')\n",
    "            num_macs_col = df.columns.get_loc(' Num MACs')\n",
    "\n",
    "            # Convert DataFrame to NumPy array for vectorized operations\n",
    "            data = df.to_numpy()\n",
    "\n",
    "            # Perform vectorized calculations\n",
    "            cycles = np.sum(data[:, runtime_col])\n",
    "            num_macs = np.sum(data[:, num_macs_col])\n",
    "            l1_access = np.sum(data[:, input_l1_read_col] + data[:, input_l1_write_col] +\n",
    "                            data[:, filter_l1_read_col] + data[:, filter_l1_write_col] +\n",
    "                            data[:, output_l1_read_col] + data[:, output_l1_write_col])\n",
    "            l2_access = np.sum(data[:, input_l2_read_col] + data[:, input_l2_write_col] + \n",
    "                            data[:, filter_l2_read_col] + data[:, filter_l2_write_col] +\n",
    "                            data[:, output_l2_read_col] + data[:, output_l2_write_col])\n",
    "            dram_access = np.sum(data[:, offchip_bw_col] * data[:, runtime_col])\n",
    "            \n",
    "            energy_nJ = num_macs * 0.48 + l1_access * 0.15 + l2_access * 3.69 + dram_access * 31.2 * 1e-3 # pJ to nJ\n",
    "            delay_s = cycles / (freq_MHz * 1e6)\n",
    "            edp_nJ = energy_nJ * delay_s\n",
    "            averaged_reuse_factor = np.mean((data[:, reuse_input_col] + data[:, reuse_filter_col] + data[:, reuse_output_col]) / 3)\n",
    "            weighted_memory_access = l1_access + 5 * l2_access + 10 * dram_access\n",
    "            leakage_mW = 100 \n",
    "            power_proxy_value = (energy_nJ) / cycles * freq_MHz + leakage_mW\n",
    "\n",
    "            # Append results for this file\n",
    "            results.append({\n",
    "                'Accelerator': accelerator,\n",
    "                'Model': model,\n",
    "                'Cycles': cycles,\n",
    "                'Runtime (s)': f\"{delay_s:.4f}\",\n",
    "                'EDP': f\"{edp_nJ:.4f}\",\n",
    "                'Memory Access': weighted_memory_access,\n",
    "                'Reuse Factor': f\"{averaged_reuse_factor:.4f}\",\n",
    "                'Power Proxy': f\"{power_proxy_value:.4f}\",\n",
    "            })\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('out/summary_results_existing_accelerators_.csv', index=False)\n",
    "\n",
    "# Display summary results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accelerator                   Model     Cycles Runtime (s)  \\\n",
      "0        nvdla  test_layer_VGG16_conv1     612721      0.0018   \n",
      "1        nvdla      test_layer_BERT_qk      13313      0.0000   \n",
      "2        nvdla     test_layer_BERT_ffn     294913      0.0008   \n",
      "3        nvdla       test_model_YOLOv8    4571206      0.0131   \n",
      "4        nvdla  test_model_MobileNetv3    1132209      0.0032   \n",
      "5        nvdla    test_model_MobileViT     323590      0.0009   \n",
      "6        nvdla        test_model_VGG16   48072056      0.1373   \n",
      "7        nvdla  test_model_InceptionV3    2843144      0.0081   \n",
      "8   shidiannao  test_layer_VGG16_conv1   15770881      0.0451   \n",
      "9   shidiannao      test_layer_BERT_qk      24576      0.0001   \n",
      "10  shidiannao     test_layer_BERT_ffn      55296      0.0002   \n",
      "11  shidiannao       test_model_YOLOv8   16137681      0.0461   \n",
      "12  shidiannao  test_model_MobileNetv3    5648773      0.0161   \n",
      "13  shidiannao    test_model_MobileViT     602112      0.0017   \n",
      "14  shidiannao        test_model_VGG16  148925953      0.4255   \n",
      "15  shidiannao  test_model_InceptionV3    7430568      0.0212   \n",
      "16     eyeriss  test_layer_VGG16_conv1     522145      0.0015   \n",
      "17     eyeriss      test_layer_BERT_qk      17408      0.0000   \n",
      "18     eyeriss     test_layer_BERT_ffn    2506753      0.0072   \n",
      "19     eyeriss       test_model_YOLOv8    7759122      0.0222   \n",
      "20     eyeriss  test_model_MobileNetv3    1757385      0.0050   \n",
      "21     eyeriss    test_model_MobileViT     450560      0.0013   \n",
      "22     eyeriss        test_model_VGG16   70662056      0.2019   \n",
      "23     eyeriss  test_model_InceptionV3    5712968      0.0163   \n",
      "\n",
      "                EDP  Memory Access Reuse Factor  Power Proxy  \n",
      "0       319596.0942      612652178      10.4925  104282.6410  \n",
      "1          221.0067       21273980       9.0024  152752.9696  \n",
      "2        25002.4025       71681750       6.0069   35215.1869  \n",
      "3     26189629.6202     7231279680       9.2958  153533.7506  \n",
      "4      1158487.2000     1269431602       8.1605  110706.7554  \n",
      "5       131316.1675      518714008       9.0229  153625.7811  \n",
      "6   1757600034.1162    42424850090       8.0206   93168.8526  \n",
      "7      6402459.9704     2853692386       8.3241   97025.3566  \n",
      "8      7874195.3562     1720559858   16430.3156    3878.2015  \n",
      "9          239.9097       31203712      43.6718   48658.8200  \n",
      "10        3915.2673       95165568       1.3939  156859.2297  \n",
      "11    56771578.1370    11086105586    7548.8898   26704.5216  \n",
      "12     5693095.8893     6759326488    1596.3620   21856.2848  \n",
      "13      143027.8123      763654400     262.3341   48328.3557  \n",
      "14  4902937480.4185   259951363322    5238.7841   27080.1876  \n",
      "15    13004490.0685    12780315864     325.1930   28852.6289  \n",
      "16      223624.4136      514906332      41.8464  100478.4799  \n",
      "17         261.1554       30588928      85.6667  105569.2235  \n",
      "18      208523.6769       72277258    1024.6667    4065.0733  \n",
      "19    40478055.3936     8821251328      58.4547   82362.6987  \n",
      "20     1524895.4581     1254123268      33.3958   60484.2541  \n",
      "21      166645.8245      949860096      77.6254  100559.9986  \n",
      "22  2003421424.2273    35003349956     421.8098   49151.3967  \n",
      "23    10268302.0276     2278826150      71.2719   38539.9494  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuration for accelerators and models\n",
    "accelerators = [\"nvdla\", \"shidiannao\", \"eyeriss\"]\n",
    "models = [\n",
    "    \"test_layer_VGG16_conv1\",\n",
    "    \"test_layer_BERT_qk\",\n",
    "    \"test_layer_BERT_ffn\",\n",
    "    \"test_model_YOLOv8\",\n",
    "    \"test_model_MobileNetv3\",\n",
    "    \"test_model_MobileViT\",\n",
    "    \"test_model_VGG16\",\n",
    "    \"test_model_InceptionV3\"\n",
    "]\n",
    "\n",
    "dataflow_mapping = {\n",
    "    \"nvdla\": \"ykp_os\",\n",
    "    \"shidiannao\": \"kcp_ws\",\n",
    "    \"eyeriss\": \"rs\"\n",
    "}\n",
    "\n",
    "freq_MHz = 350  # Frequency in MHz\n",
    "freq_Hz = freq_MHz * 1e6\n",
    "\n",
    "# Results storage\n",
    "results = []\n",
    "\n",
    "for accelerator in accelerators:\n",
    "    for model in models:\n",
    "        # Dynamically construct the file path\n",
    "        file_path = f'out/{accelerator}/{accelerator}_{model}_{dataflow_mapping[accelerator]}.csv'\n",
    "        \n",
    "        try:\n",
    "            # Read CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Extract column indices dynamically\n",
    "            runtime_col = df.columns.get_loc(' Runtime (Cycles)')\n",
    "            energy_col = df.columns.get_loc(' Activity count-based Energy (nJ)')\n",
    "            input_l1_read_col = df.columns.get_loc(' input l1 read')\n",
    "            input_l1_write_col = df.columns.get_loc(' input l1 write')\n",
    "            filter_l1_read_col = df.columns.get_loc('filter l1 read')\n",
    "            filter_l1_write_col = df.columns.get_loc(' filter l1 write')\n",
    "            output_l1_read_col = df.columns.get_loc('output l1 read')\n",
    "            output_l1_write_col = df.columns.get_loc(' output l1 write')\n",
    "            input_l2_read_col = df.columns.get_loc(' input l2 read')\n",
    "            input_l2_write_col = df.columns.get_loc(' input l2 write')\n",
    "            filter_l2_read_col = df.columns.get_loc(' filter l2 read')\n",
    "            filter_l2_write_col = df.columns.get_loc(' filter l2 write')\n",
    "            output_l2_read_col = df.columns.get_loc(' output l2 read')\n",
    "            output_l2_write_col = df.columns.get_loc(' output l2 write')\n",
    "            offchip_bw_col = df.columns.get_loc(' Offchip BW Req (Elements/cycle)')\n",
    "            reuse_input_col = df.columns.get_loc(' input reuse factor')\n",
    "            reuse_filter_col = df.columns.get_loc(' filter reuse factor')\n",
    "            reuse_output_col = df.columns.get_loc(' output reuse factor')\n",
    "            num_macs_col = df.columns.get_loc(' Num MACs')\n",
    "\n",
    "            # Convert DataFrame to NumPy array for vectorized operations\n",
    "            data = df.to_numpy()\n",
    "\n",
    "            # Perform vectorized calculations\n",
    "            cycles = np.sum(data[:, runtime_col])\n",
    "            num_macs = np.sum(data[:, num_macs_col])\n",
    "            l1_access = np.sum(data[:, input_l1_read_col] + data[:, input_l1_write_col] +\n",
    "                            data[:, filter_l1_read_col] + data[:, filter_l1_write_col] +\n",
    "                            data[:, output_l1_read_col] + data[:, output_l1_write_col])\n",
    "            l2_access = np.sum(data[:, input_l2_read_col] + data[:, input_l2_write_col] + \n",
    "                            data[:, filter_l2_read_col] + data[:, filter_l2_write_col] +\n",
    "                            data[:, output_l2_read_col] + data[:, output_l2_write_col])\n",
    "            dram_access = np.sum(data[:, offchip_bw_col] * data[:, runtime_col])\n",
    "            \n",
    "            # Calculate energy using the provided formula\n",
    "            energy_nJ = num_macs * 0.48 + l1_access * 0.15 + l2_access * 3.69 + dram_access * 31.2 * 1e-3\n",
    "            \n",
    "            # Delay and EDP calculations\n",
    "            delay_s = cycles / freq_Hz\n",
    "            edp_nJ = energy_nJ * delay_s\n",
    "            \n",
    "            # Reuse factor (average across all layers)\n",
    "            reuse_factors = (data[:, reuse_input_col] + data[:, reuse_filter_col] + data[:, reuse_output_col]) / 3\n",
    "            \n",
    "            # Average reuse factor\n",
    "            if len(data) > 1:\n",
    "                averaged_reuse_factor = np.mean(reuse_factors)\n",
    "            else:\n",
    "                averaged_reuse_factor = np.sum(reuse_factors)  # For single row, sum = original value\n",
    "            \n",
    "            # Weighted memory access (sum across all layers)\n",
    "            weighted_memory_access = l1_access + 5 * l2_access + 10 * dram_access\n",
    "            \n",
    "            # Power proxy value (average across all layers)\n",
    "            leakage_mW = 100\n",
    "            power_proxy_value = (energy_nJ / cycles) * freq_MHz + leakage_mW\n",
    "\n",
    "            # Append results for this file\n",
    "            results.append({\n",
    "                'Accelerator': accelerator,\n",
    "                'Model': model,\n",
    "                'Cycles': cycles,  # Sum\n",
    "                'Runtime (s)': f\"{delay_s:.4f}\",  # Sum\n",
    "                'EDP': f\"{edp_nJ:.4f}\",  # Sum or Mean\n",
    "                'Memory Access': weighted_memory_access,  # Sum\n",
    "                'Reuse Factor': f\"{averaged_reuse_factor:.4f}\",  # Average\n",
    "                'Power Proxy': f\"{power_proxy_value:.4f}\",\n",
    "            })\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('out/summary_results_existing_accelerators_.csv', index=False)\n",
    "\n",
    "# Display summary results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Best Fitness Score to out/generations_VGG16_conv1_best_fitness_score.csv\n",
      "Saved Best EDP to out/generations_VGG16_conv1_best_edp.csv\n",
      "Saved Best Power Proxy to out/generations_VGG16_conv1_best_power_proxy.csv\n",
      "Saved Best Reuse Factor to out/generations_VGG16_conv1_best_reuse_factor.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_metric_with_generations(dir_path, model, metric, num_generations=100):\n",
    "    # Initialize an empty list to store metrics for each file\n",
    "    metric_data = []\n",
    "    \n",
    "    # Loop through all files in the directory\n",
    "    for file_name in os.listdir(dir_path):\n",
    "        if file_name.endswith('.csv'):  # Check if it's a CSV file\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            \n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Check if the metric exists in the file\n",
    "            if metric in df.columns:\n",
    "                # Ensure the number of generations matches the expected count\n",
    "                metric_values = df[metric].tolist()[:num_generations]\n",
    "                if len(metric_values) < num_generations:\n",
    "                    # Pad with NaN if the file has fewer generations\n",
    "                    metric_values.extend([float('nan')] * (num_generations - len(metric_values)))\n",
    "                metric_data.append(metric_values)\n",
    "    \n",
    "    # Prepare the output DataFrame without generation indices\n",
    "    output_df = pd.DataFrame(metric_data)\n",
    "    \n",
    "    # Define the output path\n",
    "    output_file_name = f\"out/generations_{model}_{metric.replace(' ', '_').lower()}.csv\"\n",
    "    os.makedirs('out', exist_ok=True)  # Ensure the output directory exists\n",
    "    output_df.to_csv(output_file_name, index=False)\n",
    "    print(f\"Saved {metric} to {output_file_name}\")\n",
    "\n",
    "# Example usage\n",
    "dir_path = 'out/magneto_power_constraint/VGG16_conv1/'\n",
    "model = 'VGG16_conv1'\n",
    "metrics = ['Best Fitness Score', 'Best EDP', 'Best Power Proxy', 'Best Reuse Factor']\t\n",
    "num_generations = 100  # Adjust this if the number of generations is different\n",
    "\n",
    "for metric in metrics:\n",
    "    process_metric_with_generations(dir_path, model, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
